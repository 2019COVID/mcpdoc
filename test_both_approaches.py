#!/usr/bin/env python3
"""Test both smart query and agent choice approaches"""

import asyncio
import httpx
from markdownify import markdownify
from urllib.parse import urlparse
import re

def extract_domain(url: str) -> str:
    """Extract domain from URL."""
    parsed = urlparse(url)
    return f"{parsed.scheme}://{parsed.netloc}/"

async def test_both_approaches():
    """Test both query approaches with OpenRouter"""
    
    llms_txt_url = "https://openrouter.ai/docs/llms.txt"
    
    print("ğŸ” Testing Both MCP Documentation Query Approaches")
    print("=" * 60)
    print(f"Target: {llms_txt_url}")
    print()
    
    async with httpx.AsyncClient(timeout=10.0) as client:
        
        # Approach 1: Smart Query (Server-side matching)
        print("ğŸ“‹ APPROACH 1: Smart Query (Server-side matching)")
        print("-" * 40)
        print("Query: 'structured' â†’ automatic string matching")
        
        try:
            # Simulate query_external_docs_smart
            response = await client.get(llms_txt_url)
            response.raise_for_status()
            llms_content = response.text
            llms_domain = extract_domain(llms_txt_url)
            
            # Parse URLs
            html_urls = re.findall(r'href="([^"]*)"', llms_content)
            text_urls = re.findall(r'https?://[^\s\)\]]+', llms_content)
            
            available_urls = []
            all_found_urls = html_urls + text_urls
            
            for url in all_found_urls:
                url = url.strip().rstrip(')')
                if url.startswith('http') and url not in available_urls:
                    if url.startswith(llms_domain):
                        available_urls.append(url)
            
            # String matching
            query = "structured"
            matching_urls = []
            for url in available_urls:
                if query.lower() in url.lower():
                    matching_urls.append(url)
            
            print(f"âœ… Found {len(matching_urls)} matching URLs:")
            for url in matching_urls:
                print(f"   â€¢ {url}")
            
            if matching_urls:
                target_url = matching_urls[0]
                doc_response = await client.get(target_url)
                doc_response.raise_for_status()
                content = markdownify(doc_response.text)
                print(f"âœ… Retrieved {len(content)} characters")
                print(f"ğŸ“„ Title: {content.split('\\n')[0][:50]}...")
            
        except Exception as e:
            print(f"âŒ Error: {e}")
        
        print()
        print("=" * 60)
        
        # Approach 2: Agent Choice (List then select)
        print("ğŸ“‹ APPROACH 2: Agent Choice (List then select)")  
        print("-" * 40)
        print("Step 1: List all available docs")
        
        try:
            # Simulate list_external_docs
            print(f"ğŸ“„ Found {len(available_urls)} documentation URLs:")
            
            # Show categorized URLs for agent to choose from
            categories = {}
            for url in available_urls:
                path = url.replace(llms_domain, '').strip('/')
                category = path.split('/')[0] if '/' in path else 'general'
                if category not in categories:
                    categories[category] = []
                categories[category].append((path, url))
            
            for category, urls in categories.items():
                print(f"\\nğŸ“ {category.upper()}:")
                for path, url in urls[:3]:  # Show first 3 in each category
                    print(f"   â€¢ {path}")
                if len(urls) > 3:
                    print(f"   ... and {len(urls) - 3} more")
            
            print("\\nStep 2: Agent analyzes and selects based on semantic understanding")
            print("Agent reasoning: 'structured outputs' relates to API response formatting")
            print("Agent chooses: docs/features/structured-outputs.mdx")
            
            # Agent's choice
            target_url = "https://openrouter.ai/docs/features/structured-outputs.mdx"
            print(f"\\nğŸ“– Fetching agent's choice: {target_url}")
            
            doc_response = await client.get(target_url)
            doc_response.raise_for_status()
            content = markdownify(doc_response.text)
            print(f"âœ… Retrieved {len(content)} characters")
            print(f"ğŸ“„ Title: {content.split('\\n')[0][:50]}...")
            
        except Exception as e:
            print(f"âŒ Error: {e}")
        
        print()
        print("=" * 60)
        print("ğŸ“Š COMPARISON:")
        print("Smart Query    â†’ Fast, limited to URL string matching")
        print("Agent Choice   â†’ Flexible, enables semantic reasoning")
        print("Use Smart for  â†’ Simple, direct queries ('auth', 'api')")  
        print("Use Agent for  â†’ Complex queries ('JSON validation', 'type safety')")

if __name__ == "__main__":
    asyncio.run(test_both_approaches())